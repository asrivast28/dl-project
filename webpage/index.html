<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Deep Learning Class Project
  | Georgia Tech | Fall 2018: CS 4803 / 7643</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>On Improving Unsupervised Learning with DeepCluster</h1>
<span style="font-size: 20px; line-height: 1.5em;"><strong>Srinivas Eswar, Ankit Srivastava, Chunxing Yin</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2018 CS 4803 / 7643 Deep Learning: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

This webpage template is based on a similar template from Dr. Devi Parikh's
<a href="https://samyak-268.github.io/F18CS4476/">Intro to Computer Vision course</a>.

<!-- Goal -->
<h2>Abstract</h2>

One or two sentences on the motivation behind the problem you are solving. One or two sentences describing the approach you took. One or two sentences on the main result you obtained.
<br><br>
<!-- figure -->
<!--<h2>Teaser figure</h2>-->
<!--A figure that conveys the main idea behind the project or the main application being addressed. (This one is from <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a>.)-->
<!-- Main Illustrative Figure --> 
<div style="text-align: center;">
  <img style="height: 300px;" alt="" src="images/deepcluster_training.png">
  <figcaption>Fig.1 - Unsupervised training approach used by DeepCluster [1]</figcaption>
</div>

<br><br>
<!-- Introduction -->
<h2>Introduction / Background / Motivation</h2>
<!--Previous works [cite] have shown that it is possible adapt density estimation or dimensionality reduction to supervised deep learning models,-->
<!--to produce a promising image classification on unlabeled data. In this project, we study the result in [1], DeepCluster, which uses the <i>k</i>-means cluster assignments on-->
<!--convnet features as pseudo-labels to learn the parameters for the convolutional neural network.-->

<h4>What did you try to do? What problem did you try to solve? Articulate your objectives using absolutely no jargon. (5 points)</h4>
Datasets used in the state-of-the-art neural network training, even ImageNet [2] which contains millions of images, are relatively small as compared to the capacity of the current networks.
But, building larger labeled datasets for supervised learning requires a tremendous amount of manual work.
Therefore, a natural way forward is to train on massive unlabeled datasets using unsupervised learning [4].
However, currently, there is an accuracy gap between the accuracy of models trained using unsupervised learning as compared to those trained using supervised learning.
For example, the difference between the accuracy of supervised AlexNet [2] and unsupervised DeepCluster [1] on classifying images in the ImageNet dataset is between 3% to 12%.
This gap needs to be closed for the unsupervised learning based approaches to gain popular acceptance.
<br><br>
In this project, we attempted to close this gap by trying to improve the methodology used in the state-of-the-art in unsupervised learning, i.e., DeepCluster [1].
The training method in [1] relies on generating "pseudo-labels" for images and then using these labels for training the network iteratively.
Specifically, we set out to confirm our intuition about some problems with the way the pseudo-labels for images are generated in [1] and, then, explore different ideas to address those problems.
We hoped that this would improve the accuracy of models trained using unsupervised learning methods for the image classification task.
 <!--In this project, we will only discuss the influence of permuted labels on the deep learning networks.-->
<!--We explore if the instability of k-means affect the accuracy of such approach, and we propose [2?] methods to stabilize the pseudo-labels to improve the accuracy of the convnet.-->
<!--In this project, we also study the relevance between stability of the correct labels and the behavior of various popular networks.-->


<h4>How is it done today, and what are the limits of current practice? (5 points)</h4>
The unsupervised learning in [1] is done by alternating between the following two steps:
<ol type="i">
  <li> Output features for all the training images are generated by doing a forward pass through the model. These features are then clustered using <i>k</i>-means clustering algorithm. The cluster assignments are used
    as pseudo-labels for the corresponding training images.
  <li> The pseudo-labels generated in the previous step are used for updating the model parameters with one pass through the training dataset.
</ol>
The above steps are repeated until some convergence criterion is satisfied. This methodology is visualized in Fig. 1.
<br><br>
Based on our prior experience with the <i>k</i>-means algorithm, we suspected that the algorithm labels clusters in a non-deterministic way, i.e., given the same features,
the algorithm can permute the pseudo-labels assigned to images across epochs. This means that, for example, in a case with three clusters, the output cluster assignment can be any arbitrary mapping of the ordered set (0, 1, 2).
Since the loss function used in [1] is not permutation invariant, we conjectured that if the pseudo-labels are indeed getting permuted then it would lead to the loss of accuracy and also increase the training time of the models.


<h4>Who cares? If you are successful, what difference will it make? (5 points)</h4>
Our project is aimed at improving the accuracy of the state-of-the-art in unsupervised learning methods. As discussed earlier, the accuracy gap between supervised and unsupervised learning methods
is hindering widespread acceptance of the unsupervised learning methods. If the work done in this project makes a step towards closing this gap, then that would assist in a move towards using larger
unlabeled datasets which can utilize current capacity of neural networks.
The training time of the models using unsupervised learning would also be reduced, which will further its appeal.
Moreover, this would allow existing stable supervised learning networks to be extended using unsupervised learning on pseudo-labels.

<br><br>
<!-- Approach -->
<h2>Approach</h2>
DeepCluster uses a standard AlexNet architecture which consists of five convolutional layers with 96, 256, 383, 384, and 256 filters; and three fully connected layers.
The original experiments trains for 500 epochs on ImageNet, which takes 12 days on a Pascal P100 GPU. :
Due to the limited time and resources, we scale down the size of each problem as follows:
<ul>
  <li>Run k-means on a randomly generated mixture of Gaussians
  <li>Permuting the target labels during traning VGG [5], ResNet [6], twoLayerNN for both CIFAR-10 and CIFAR-100 [7].
</ul>

<h4>What did you do exactly? How did you solve the problem? Why did you think it would be successful? Is anything new in your approach? (10 points)</h4>
The purpose of this project was to improve the accuracy of classification achieved in [1]. We believed that this was an attainable objective because of the following two key intuitions about the approach
used in [1] for training the model: 1) the labels generated by <i>k</i>-means clustering can permute across runs, and 2) permuting the target labels during training will have a detrimental effect on the model.
Since our claims were based on conjecture, we first had to prove that our intuitions were correct. Therefore, we separated the project into the following three tasks:
<ol type="1">
  <li>Verify that the labels generated by <i>k</i>-means algorithm are indeed permuted randomly.</li>
  <li>Explore the influence of permuting labels every epoch when training the network.</li>
  <li>If the above two tasks match our conjecture, then try to stabilize the output of <i>k</i>-means to improve the overall accuracy.</li>
</ol>
Below, we describe our methodology for the three tasks in detail.
<br>
<h5> 1. Generate a mixture of Gaussians and use <i>k</i>-means algorithm to cluster it. </h5>
As described earlier, cluster assignments generated by the <i>k</i>-means algorithm are used as pseudo-labels for training the model. We surmised that the cluster assignments generated by the algorithm are arbitrary
and can permute across runs. In order to verify this, we generated a small toy example using mixture of Gaussians that can be easily seperated by <i>k</i>-means algorithm to prevent different runs of the algorithm
from converging to different local optima. We define the degree of permutation of the centroids <img src="http://latex.codecogs.com/gif.latex?\{c_1, c_2, ..., c_n\}" border="0"/> to be
<br><br>
<center>
  <img src="http://latex.codecogs.com/gif.latex?f(C) = ||c_i - c^*_i||_2" border="0"/>, <br>
</center>
<br>
where <i>c<cap>*</cap><sub>i</sub>'s</i> are obtained by ordering <i>c'<sub>i</sub>'s</i>.
Since <i>c<cap>*</cap><sub>i</sub>'s</i> are guaranteed to be the same during all executions, this method measures how different <i>k</i>-means algorithm labels the clusters.

<h5> 2. the labels generated by <i>k</i>-means clustering can permute across runs </h5>
As described earlier, cluster assignments generated by the <i>k</i>-means algorithm are used as pseudo-labels for training the model. We surmised that the cluster assignments generated by the algorithm are arbitrary
and can permute across runs. We confirmed our intuition by running <i>k</i>-means algorithm on toy datasets, the results of which are described later.

<h5> 3. permuting the target labels during training should have a detrimental effect on the model </h5>
Second, permuting the labels of classes between epochs should lead to a reduction
in the classification accuracy achieved by the neural network.

<h4>What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work? (5 points)</h4>
Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.

<br><br>
<!-- Results -->
<h2>Experiments and Results</h2>
<h4>How did you measure success? What experiments were used? What were the results, both quantitative and qualitative? Did you succeed? Did you fail? Why? (10 points)</h4>
Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.

<br><br>

<!-- Main Results Figure -->
<h5> 1. Label stability via <i>k</i>-means clustering </h5>
Our first experiment was to check if the <i>k</i>-means algorithm permutes clusters across multiple iterations. We generated a toy dataset comprising of 3 clusters drawn from Guassian Distributions with different centres. We then ran the <i>k</i>-means algorithm for 10 iterations and checked the Frobenius norm difference between the centroids discoverd from the original centroids. We also sort the centroids lexicographically and plot the Frobenius difference. As seen from the figure below even though the algorithm successfully discovered the correct centroids for every run there is still a large error when compared to the original centroids unless they are sorted to avoid permutations.
<div class="row" style="text-align: center;">
  <div class="column">
    <img style="height:350px; width:85%" alt="" src="images/gmmdat.pdf">
  </div>

  <div class="column">
    <img style="height:340px; width:100%" alt="" src="images/gmmpermerr.pdf">
  </div>
</div>
<br><br>

<br><br>

<div class="row" style="text-align: center;">
  <div class="column">
    <img style="height:350px; width:85%" alt="" src="images/convnet_test_acc.png">
  </div>

  <div class="column">
    <img style="height:340px; width:100%" alt="" src="images/resnet_test_acc.png">
  </div>
</div>
<br><br>

<br><br>
<h3>References</h3>
<ol type="1">
  <li> Caron, Mathilde, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. "Deep Clustering for Unsupervised Learning of Visual Features." In <i>Computer Vision–ECCV 2018</i>, pp. 139-156. Springer, Cham, 2018.</li>
  <li> Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." In <i>Advances in neural information processing systems</i>, pp. 1097-1105. 2012.</li>
  <li> Deng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. "Imagenet: A large-scale hierarchical image database." In <i>Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on</i>, pp. 248-255. Ieee, 2009.</li>
  <li> Coates, Adam, and Andrew Y. Ng. "Learning feature representations with k-means." In <i>Neural networks: Tricks of the trade</i>, pp. 561-580. Springer, Berlin, Heidelberg, 2012. </li>
  <li> Simonyan, Karen, and Andrew Zisserman. "Very deep convolutional networks for large-scale image recognition." <i>arXiv preprint arXiv:1409.1556</i> (2014). </li>
  <li> He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. "Deep residual learning for image recognition." In <i>Proceedings of the IEEE conference on computer vision and pattern recognition</i>, pp. 770-778. 2016. </li>
  <li> Krizhevsky, Alex, Vinod Nair, and Geoffrey Hinton. "The CIFAR-10 dataset." <i>online: http://www.cs.toronto.edu/kriz/cifar.html</i> (2014).</li>
</ol>

<!-- Additional Points to Consider (REMOVE BEFORE SUBMISSION) -->
<h2> Additional Points to Consider (REMOVE BEFORE SUBMISSION)</h2>
<h4>Appropriate use of visual aids. Are the ideas presented with appropriate illustration? Is the problem effectively visualized? Is the approach visualized appropriately? Are the results presented clearly; are the important differences illustrated? Every section and idea does not need a visual aid, but the most interesting and complex parts of the project should be illustrated. (5 points)</h4>
Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.

<h4>Overall clarity. Is the presentation clear? Can a peer who has also taken Deep Learning understand all of the points addressed above? Is sufficient detail provided? (5 points)</h4>
Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.

<h4>Finally, points will be distributed based on your understanding of how your project relates to Deep Learning. Here are some questions to think about: (10 points)</h4>
<ul>
  <li>What was the structure of your problem? How did the structure of your model reflect the structure of your problem?</li>
  <li>What parts of your model had learned parameters (e.g., convolution layers) and what parts did not (e.g., post-processing classifier probabilities into decisions)?</li>
  <li>What representations of input and output did the neural network expect? How was the data pre/post-processed?</li>
  <li>What was the loss function?</li>
  <li>Did the model overfit? How well did the approach generalize?</li>
  <li>What hyperparameters did the model have? How were they chosen? How did they affect performance? What optimizer was used?</li>
  <li>What Deep Learning framework did you use?</li>
  <li>What existing code or models did you start with and what did those starting points provide?</li>
</ul>
At least some of these questions and others should be relevant to your project and should be addressed in the webpage. You do not need to address all of them in full detail. Some may be irrelevant to your project and others may be standard and thus require only a brief mention. For example, it is sufficient to simply mention the cross-entropy loss was used and not provide a full description of what that is. Generally, provide enough detail that someone with an appropriate background (in both Deep Learning and your domain of choice) could replicate the main parts of your project somewhat accurately, probably missing a few less important details.

<br><br>

  <hr>
  <footer> 
  <p>© Srinivas Eswar, Ankit Srivastava, Chunxing Yin</p>
  </footer>
</div>
</div>

<br><br>

</body></html>

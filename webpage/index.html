<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Deep Learning Class Project
  | Georgia Tech | Fall 2018: CS 4803 / 7643</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Your Title Here</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Srinivas Eswar, Ankit Srivastava, Chunxing Yin</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2018 CS 4803 / 7643 Deep Learning: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

This webpage template is based on a similar template from Dr. Devi Parikh's
<a href="https://samyak-268.github.io/F18CS4476/">Intro to Computer Vision course</a>.

<!-- Goal -->
<h2>Abstract</h2>

One or two sentences on the motivation behind the problem you are solving. One or two sentences describing the approach you took. One or two sentences on the main result you obtained.
<br><br>
<!-- figure -->
<h2>Teaser figure</h2>
A figure that conveys the main idea behind the project or the main application being addressed. (This one is from <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">AlexNet</a>.)
<br><br>
<!-- Main Illustrative Figure --> 
<div style="text-align: center;">
<img style="height: 200px;" alt="" src="images/alexnet.png">
</div>

<br><br>
<!-- Introduction -->
<h2>Introduction / Background / Motivation</h2>
Previous works [cite] have shown that it is possible adapt density estimation or dimensionality reduction to supervised deep learning models,
to produce a promising image classification on unlabeled data. In this project, we study the result in [1], DeepCluster, which uses the <i>k</i>-means cluster assignments on
convnet features as pseudo-labels to learn the parameters for the convolutional neural network. We will describe this approach in detail in the next section.

<h4>What did you try to do? What problem did you try to solve? Articulate your objectives using absolutely no jargon. (5 points)</h4>
As is reported in [1], there is a 3% to 12% accuracy gap between unsupervised DeepCluster[1] and supervised AlexNet[2] on the ImageNet[3] dataset.
We conjectured that inaccuracy of the pseudo-labels results in the loss of accuracy. In this project, we will only discuss the influence of permuted labels on the deep learning networks.
We explore if the instability of k-means affect the accuracy of such approach, and we propose [2?] methods to stabilize the pseudo-labels to improve the accuracy of the convnet.
In this project, we also study the relevance between stability of the correct labels and the behavior of various popular networks.

<h4>How is it done today, and what are the limits of current practice? (5 points)</h4>
The unsupervised learning in [1] is done by alternating between the following two steps:
<ol type="i">
  <li> Output features for all the training images are generated by doing a forward pass through the model. These features are then clustered using <i>k</i>-means clustering algorithm. The cluster assignments are used
    as pseudo-labels for the corresponding training images.
  <li> The pseudo-labels generated in the previous step are used for updating the model parameters with one pass through the training dataset.
</ol>
The above steps are repeated until some convergence criterion is satisfied. However, we demonstrate later that <i>k</i>-means algorithm labels clusters in a non-deterministic way, i.e., given the same features,
the algorithm can permute pseudo-labels across epochs. Since the loss function is not permutation invariant, permuting the pseudo-labels increases the loss and convergence time [true??] of the deep networks.

<h4>Who cares? If you are successful, what difference will it make? (5 points)</h4>
Datasets used in state-of-art machine learning trainings, even ImageNet which contains millions of images, is relatively small by today’s standards.
Building larger datasets will require tremendous amount of manual work. A natural way to move forward is to train massive size dataset with unsupervised network.[4] 
If our experiments succeed, we will be able to increase the accuracy of DeepCluster, which outperforms all the state-of-the-art unsupervised learning methods.
Moreover, we will explore more stable existing supervised learning networks that can be applied with pseudo-labels and extend them to be unsupervised.

<br><br>
<!-- Approach -->
<h2>Approach</h2>
<h4>What did you do exactly? How did you solve the problem? Why did you think it would be successful? Is anything new in your approach? (10 points)</h4>
The purpose of this project was to improve upon the accuracy of classification achieved in [1]. We believed that this was an attainable objective because of the following two key intuitions about the approach 
used in [1] for training the model:
<h5> 1. the labels generated by <i>k</i>-means clustering can permute across runs </h5>
As described earlier, cluster assignments generated by the <i>k</i>-means algorithm are used as pseudo-labels for training the model. We surmised that the cluster assignments generated by the algorithm are arbitrary
and can permute across runs. We confirmed our intuition by running <i>k</i>-means algorithm on toy datasets, the results of which are described later.

<h5> 2. permuting the target labels during training should have a detrimental effect on the model </h5>
. Second, permuting the labels of classes between epochs should lead to a reduction
in the classification accuracy achieved by the neural network.

<h4>What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work? (5 points)</h4>
Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.

<br><br>
<!-- Results -->
<h2>Experiments and Results</h2>
<h4>How did you measure success? What experiments were used? What were the results, both quantitative and qualitative? Did you succeed? Did you fail? Why? (10 points)</h4>
Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.

<br><br>

<!-- Main Results Figure --> 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="images/results.png">
</div>
<br><br>

<br><br>
<h3>References</h3>
<ol type="1">
  <li> Caron, Mathilde, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. "Deep Clustering for Unsupervised Learning of Visual Features." In <i>Computer Vision–ECCV 2018</i>, pp. 139-156. Springer, Cham, 2018.</li>
  <li> Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." In <i>Advances in neural information processing systems</i>, pp. 1097-1105. 2012.</li>
  <li> Deng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. "Imagenet: A large-scale hierarchical image database." In <i>Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on</i>, pp. 248-255. Ieee, 2009.</li>
  <li> Coates, Adam, and Andrew Y. Ng. "Learning feature representations with k-means." In <i>Neural networks: Tricks of the trade</i>, pp. 561-580. Springer, Berlin, Heidelberg, 2012. </li>
</ol>

<!-- Additional Points to Consider (REMOVE BEFORE SUBMISSION) -->
<h2> Additional Points to Consider (REMOVE BEFORE SUBMISSION)</h2>
<h4>Appropriate use of visual aids. Are the ideas presented with appropriate illustration? Is the problem effectively visualized? Is the approach visualized appropriately? Are the results presented clearly; are the important differences illustrated? Every section and idea does not need a visual aid, but the most interesting and complex parts of the project should be illustrated. (5 points)</h4>
Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.

<h4>Overall clarity. Is the presentation clear? Can a peer who has also taken Deep Learning understand all of the points addressed above? Is sufficient detail provided? (5 points)</h4>
Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.

<h4>Finally, points will be distributed based on your understanding of how your project relates to Deep Learning. Here are some questions to think about: (10 points)</h4>
<ul>
  <li>What was the structure of your problem? How did the structure of your model reflect the structure of your problem?</li>
  <li>What parts of your model had learned parameters (e.g., convolution layers) and what parts did not (e.g., post-processing classifier probabilities into decisions)?</li>
  <li>What representations of input and output did the neural network expect? How was the data pre/post-processed?</li>
  <li>What was the loss function?</li>
  <li>Did the model overfit? How well did the approach generalize?</li>
  <li>What hyperparameters did the model have? How were they chosen? How did they affect performance? What optimizer was used?</li>
  <li>What Deep Learning framework did you use?</li>
  <li>What existing code or models did you start with and what did those starting points provide?</li>
</ul>
At least some of these questions and others should be relevant to your project and should be addressed in the webpage. You do not need to address all of them in full detail. Some may be irrelevant to your project and others may be standard and thus require only a brief mention. For example, it is sufficient to simply mention the cross-entropy loss was used and not provide a full description of what that is. Generally, provide enough detail that someone with an appropriate background (in both Deep Learning and your domain of choice) could replicate the main parts of your project somewhat accurately, probably missing a few less important details.

<br><br>

  <hr>
  <footer> 
  <p>© Srinivas Eswar, Ankit Srivastava, Chunxing Yin</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
